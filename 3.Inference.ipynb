{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.Inference.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+WoOiGPeN4BzkEmfw3NI2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"bhGtiI_hVyZ1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EV0KhjpDWFVn","colab_type":"text"},"source":["## Step 1: Get Data Loader for Test Dataset\n"]},{"cell_type":"code","metadata":{"id":"74S6Hc6GWI3T","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/opt/cocoapi/PythonAPI')\n","from pycocotools.coco import COCO\n","from data_loader import get_loader\n","from torchvision import transforms\n","\n","# TODO #1: Define a transform to pre-process the testing images.\n","\n","transform_test = transforms.Compose([ \n","    transforms.Resize(256),                     \n","    transforms.RandomCrop(224),                      \n","    transforms.ToTensor(),                          \n","    transforms.Normalize((0.485, 0.456, 0.406),      \n","                         (0.229, 0.224, 0.225))])\n","\n","\n","\n","#-#-#-# Do NOT modify the code below this line. #-#-#-#\n","\n","# Create the data loader.\n","data_loader = get_loader(transform=transform_test,    \n","                         mode='test')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xpJ0bR7vWMUu","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Obtain sample image before and after pre-processing.\n","orig_image, image = next(iter(data_loader))\n","\n","# Visualize sample image, before pre-processing.\n","plt.imshow(np.squeeze(orig_image))\n","plt.title('example image')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RY4ouoORWPgq","colab_type":"text"},"source":["## Step 2: Load Trained Models\n"]},{"cell_type":"code","metadata":{"id":"BLZUafeJWOik","colab_type":"code","colab":{}},"source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BktmKTE0WOkt","colab_type":"code","colab":{}},"source":["# Watch for any changes in model.py, and re-load it automatically.\n","% load_ext autoreload\n","% autoreload 2\n","\n","import os\n","import torch\n","from model import EncoderCNN, DecoderRNN\n","\n","# TODO #2: Specify the saved models to load.\n","encoder_file = 'encoder-3.pkl'\n","decoder_file = 'decoder-3.pkl'\n","\n","\n","# TODO #3: Select appropriate values for the Python variables below.\n","\n","embed_size = 256\n","hidden_size = 512\n","\n","\n","\n","\n","# The size of the vocabulary.\n","vocab_size = len(data_loader.dataset.vocab)\n","\n","# Initialize the encoder and decoder, and set each to inference mode.\n","encoder = EncoderCNN(embed_size)\n","encoder.eval()\n","decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n","decoder.eval()\n","\n","# Load the trained weights.\n","encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n","decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n","\n","# Move models to GPU if CUDA is available.\n","encoder.to(device)\n","decoder.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfbSF-vCWXcL","colab_type":"text"},"source":["## Step 3: Finish the Sampler\n"]},{"cell_type":"code","metadata":{"id":"TLaZGb1RWOmx","colab_type":"code","colab":{}},"source":["# Move image Pytorch Tensor to GPU if CUDA is available.\n","image = image.to(device)\n","\n","# Obtain the embedded image features.\n","features = encoder(image).unsqueeze(1)\n","\n","# Pass the embedded image features through the model to get a predicted caption.\n","output = decoder.sample(features)\n","print('example output:', output)\n","\n","assert (type(output)==list), \"Output needs to be a Python list\" \n","assert all([type(x)==int for x in output]), \"Output should be a list of integers.\" \n","assert all([x in data_loader.dataset.vocab.idx2word for x in output]), \"Each entry in the output needs to correspond to an integer that indicates a token in the vocabulary.\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4SDT87ZWcnr","colab_type":"text"},"source":["## Step 4: Clean up the Captions\n"]},{"cell_type":"code","metadata":{"id":"jfcsmhVmWMXT","colab_type":"code","colab":{}},"source":["# TODO #4: Complete the function.\n","\n","def clean_sentence(output):\n","    sentence = ''\n","    for i in output:\n","        word = data_loader.dataset.vocab.idx2word[i]\n","        if i == 0:\n","            continue\n","        elif i == 1:\n","            break\n","        elif i == 18:\n","            sentence = sentence + word\n","        else :\n","            sentence = sentence + ' ' + word\n","    \n","    return sentence.strip()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3SD9KRBWMZp","colab_type":"code","colab":{}},"source":["sentence = clean_sentence(output)\n","print('example sentence:', sentence)\n","\n","assert type(sentence)==str, 'Sentence needs to be a Python string!'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PgEKxqFGWkUH","colab_type":"text"},"source":["## Step 5: Generate Predictions!\n"]},{"cell_type":"code","metadata":{"id":"-6E1IZy9WMcY","colab_type":"code","colab":{}},"source":["def get_prediction():\n","    orig_image, image = next(iter(data_loader))\n","    plt.imshow(np.squeeze(orig_image))\n","    plt.title('Sample Image')\n","    plt.show()\n","    image = image.to(device)\n","    features = encoder(image).unsqueeze(1)\n","    output = decoder.sample(features)    \n","    sentence = clean_sentence(output)\n","    print(sentence)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWTUwJ92WjW3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhT6z8QpWjZZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9S6I9H-RWjeP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}