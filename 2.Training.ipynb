{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.Training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPcfKPIdf9lRuBe95LIcK8+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"uxuEFhABU4ce","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","import sys\n","sys.path.append('/opt/cocoapi/PythonAPI')\n","from pycocotools.coco import COCO\n","from data_loader import get_loader\n","from model import EncoderCNN, DecoderRNN\n","import math\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIsdhAfdVFie","colab_type":"code","colab":{}},"source":["# DecoderRNN.download('all')\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('all')\n","\n","## TODO #1: Select appropriate values for the Python variables below.\n","batch_size = 64          \n","vocab_threshold = 5        \n","vocab_from_file = False    \n","embed_size = 256    \n","hidden_size = 512          \n","num_epochs = 3            \n","save_every = 1            \n","print_every = 100        \n","log_file = 'training_log.txt'       \n","\n","# (Optional) TODO #2: Amend the image transform below.\n","transform_train = transforms.Compose([ \n","    transforms.Resize(256),                          \n","    transforms.RandomCrop(225),                      \n","    transforms.RandomHorizontalFlip(),               \n","    transforms.ToTensor(),                           \n","    transforms.Normalize((0.485, 0.456, 0.406),      \n","                         (0.229, 0.224, 0.225))])\n","\n","# Build data loader.\n","data_loader = get_loader(transform=transform_train,\n","                         mode='train',\n","                         batch_size=batch_size,\n","                         vocab_threshold=vocab_threshold,\n","                         vocab_from_file=vocab_from_file)\n","\n","# The size of the vocabulary.\n","vocab_size = len(data_loader.dataset.vocab)\n","\n","# Initialize the encoder and decoder. \n","encoder = EncoderCNN(embed_size)\n","decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n","\n","# Move models to GPU if CUDA is available. \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","encoder.to(device)\n","decoder.to(device)\n","\n","# Define the loss function. \n","criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n","\n","# TODO #3: Specify the learnable parameters of the model.\n","params = list(decoder.parameters()) + list(encoder.embed.parameters())\n","\n","\n","# TODO #4: Define the optimizer.\n","optimizer = torch.optim.Adam(params) #, lr=.005)\n","\n","# Set the total number of training steps per epoch.\n","                       \n","total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3OdSBMvuVMxr","colab_type":"text"},"source":["## Step 2: Train your Model\n"]},{"cell_type":"code","metadata":{"id":"W_ptKExdVLah","colab_type":"code","colab":{}},"source":["import torch.utils.data as data\n","import numpy as np\n","import os\n","import requests\n","import time\n","\n","# Open the training log file.\n","f = open(log_file, 'w')\n","\n","old_time = time.time()\n","response = requests.request(\"GET\", \n","                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n","                            headers={\"Metadata-Flavor\":\"Google\"})\n","\n","for epoch in range(1, num_epochs+1):\n","    \n","    for i_step in range(1, total_step+1):\n","        \n","        if time.time() - old_time > 60:\n","            old_time = time.time()\n","            requests.request(\"POST\", \n","                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n","                             headers={'Authorization': \"STAR \" + response.text})\n","        \n","        # Randomly sample a caption length, and sample indices with that length.\n","        indices = data_loader.dataset.get_train_indices()\n","        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n","        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n","        data_loader.batch_sampler.sampler = new_sampler\n","        \n","        # Obtain the batch.\n","        images, captions = next(iter(data_loader))\n","\n","        # Move batch of images and captions to GPU if CUDA is available.\n","        images = images.to(device)\n","        captions = captions.to(device)\n","        \n","        # Zero the gradients.\n","        decoder.zero_grad()\n","        encoder.zero_grad()\n","        \n","        # Pass the inputs through the CNN-RNN model.\n","        features = encoder(images)\n","        outputs = decoder(features, captions)\n","        \n","        # Calculate the batch loss.\n","        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n","        \n","        # Backward pass.\n","        loss.backward()\n","        \n","        # Update the parameters in the optimizer.\n","        optimizer.step()\n","            \n","        # Get training statistics.\n","        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n","        \n","        # Print training statistics (on same line).\n","        print('\\r' + stats, end=\"\")\n","        sys.stdout.flush()\n","        \n","        # Print training statistics to file.\n","        f.write(stats + '\\n')\n","        f.flush()\n","        \n","        # Print training statistics (on different line).\n","        if i_step % print_every == 0:\n","            print('\\r' + stats)\n","            \n","    # Save the weights.\n","    if epoch % save_every == 0:\n","        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n","        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n","\n","# Close the training log file.\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f4JnjLFtVSkV","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"siaZO5duVRlF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MISRdelxVRnf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"drtK7cQ2VRpt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSs5XFtxVLdG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5n9bKu5VLfp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QCSdcRNdVFlM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjCXEF_CVFnx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J3BUVdVaVFqP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOj6_3xtVFst","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNozde8FVFvP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}